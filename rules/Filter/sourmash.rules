###########################################
## Filter genomes further using sourmash ##
###########################################

rule sourmash_hash_genomes:
    """Compute k-mer signatures for filtered genomes"""
    input:
        opj(config["results_path"],"centrifuge","filtered","genomes.fna"),
        opj(config["results_path"],"centrifuge","{sample}_se.filtered_genomes")
    output:
        fna = opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.fna"),
        sig = opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.sig")
    params:
        hash_fraction = config["sourmash_fraction"],
        seqids = temp(opj(config["results_path"],"centrifuge","filtered","{sample}_se.seqids")),
        in_dir = opj(config["results_path"],"centrifuge","filtered")
    resources:
        runtime = lambda wildcards, attempt: attempt**2*60*2
    run:
        df = pd.DataFrame()
        _df = pd.read_csv(input[1], sep="\t")
        df = pd.concat([df,_df], sort=True)
        # Make unique by seqid
        df = df.groupby("seq").first().reset_index()
        # Write seqids to file
        with open(params.seqids, 'w') as fhout:
            for seqid in df.seq:
                fhout.write("{}\n".format(seqid))

        # Extract sequences to individual sample
        shell("seqtk subseq {input[0]} {params.seqids} > {output.fna}")
        shell("sourmash compute --singleton -k 31 --scaled {params.hash_fraction} -o {output.sig} -f {output.fna}")
        

rule sourmash_hash_sample_se:
    """Compute k-mer signatures for single-end samples"""
    input:
        opj(config["results_path"],"centrifuge","{sample}_se.filtered.fq")
    output:
        opj(config["results_path"],"sourmash","{sample}_se.sig")
    params:
        hash_fraction = config["sourmash_fraction"]
    resources:
        runtime = lambda wildcards, attempt: attempt**2*60*2
    shell:
        """
        sourmash compute -k 31 --scaled {params.hash_fraction} --merge {wildcards.sample} \
        -o {output[0]} {input}
        """

rule sourmash_coverage:
    """Calculate coverage of filtered genomes for each sample"""
    input:
        sample = opj(config["results_path"],"sourmash","{sample}_se.sig"),
        genome = opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.sig")
    output:
        opj(config["results_path"],"centrifuge","filtered","{sample}_se.sourmash.csv")
    resources:
        runtime = lambda wildcards, attempt: attempt**2*60

    ### --threshold-bp 1000 because in viral metagenomics, only several kilo bp overlap could be identified
    shell:
        """
        sourmash gather --threshold-bp 1000 -o {output[0]} -k 31 {input.sample} {input.genome}
        """

#rule collate_sourmash:
#    """Collate all sourmash coverage files"""
#    input:
#        expand(opj(config["results_path"],"centrifuge","filtered","{sample}_se.csv"),sample=Samples.keys())
#    output:
#        opj(config["results_path"],"centrifuge","filtered","sourmash.csv")
#    run:
#        df = pd.DataFrame()
#        for f in input:
#            sample_run = os.path.basename(f).rstrip(".csv")
#            _df = pd.read_csv(f, header=0)
#            _df = _df.assign(sample=pd.Series([sample_run]*len(_df)))
#            df = pd.concat([df,_df])
#        df.set_index("sample")
#        df.to_csv(output[0], index=True, header=True)

rule sourmash_filter:
    """Reads results from sourmash and outputs a fasta file with genomes reaching a certain coverage threshold"""
    input:
        opj(config["results_path"],"centrifuge","filtered","{sample}_se.sourmash.csv"),
        opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.fna"),
        opj(config["taxdb"],"taxonomy","taxdb.sqlite"),
        opj(config["results_path"],"centrifuge","{sample}_se.filtered_genomes")
    output:
        opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.filtered.fna"),
        opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.filtered.ids.tax"),
        temp(opj(config["results_path"],"centrifuge","filtered","{sample}_se.genomes.filtered.ids"))
    params:
        min_cov = config["sourmash_min_cov"]
    run:
        from ete3 import NCBITaxa
        ncbi = NCBITaxa(input[2])

        df = pd.read_csv(input[0])
        temp = df.loc[df.f_match>=params.min_cov]

        # if no genomes meet coverage requirement, then all candidate genomes are used for mapping
        if temp.empty: pass
        else: df = temp

        ids = list(set([x.split(" ")[0] for x in df.name]))

        seqid2taxid = pd.read_csv(input[3], sep="\t")
        # Make unique by seqid
        seqid2taxid = seqid2taxid.groupby("seq").first().reset_index()
        
        taxids = seqid2taxid.loc[seqid2taxid['seq'].isin(ids)].taxID
        taxids = list(set(taxids))
        taxnames = pd.DataFrame(columns=["taxID","Name","Genus","Family","Kingdom"])
        for taxid in taxids:
            lineage = ncbi.get_lineage(taxid)
            ranks = ncbi.get_rank(lineage)

            genus_name = ""
            family_name = ""
            kingdom_name = ""
            for key, value in ranks.items():
                if(value == "genus"): genus_name = ncbi.get_taxid_translator([key]).get(key)
                if(value == "family"): family_name = ncbi.get_taxid_translator([key]).get(key)
                if(value == "superkingdom"): kingdom_name = ncbi.get_taxid_translator([key]).get(key)
            
            tmp = pd.Series([taxid,ncbi.get_taxid_translator([taxid]).get(taxid),genus_name,family_name,kingdom_name],index=["taxID","Name","Genus","Family","Kingdom"])
            taxnames = taxnames.append(tmp,ignore_index=True)
        
        ids2tax = pd.merge(seqid2taxid,taxnames,on="taxID")
        ids2tax = ids2tax.groupby("seq").first().reset_index()
        ids2tax.to_csv(output[1],sep="\t",index=False)

        with open(output[2], 'w') as fhout:
            for id in ids:
                fhout.write("{}\n".format(id))
        shell("seqtk subseq {input[1]} {output[2]} > {output[0]}")
