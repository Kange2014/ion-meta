localrules:
    centrifuge2krona,
    centrifuge_kreport,
    all_centrifuge_to_krona,
    centrifuge_filter


############################
## Centrifuge classifying ##
############################

rule centrifuge_map_se:
    input:
        opj(config["data_path"],"{sample}_se.fq"),
        expand(opj(config["centrifuge_dir"],"{base}.{i}.cf"), i=[1,2,3], base=config["centrifuge_base"])
    output:
        opj(config["results_path"],"centrifuge","{sample}_se.out"),
        opj(config["results_path"],"centrifuge","{sample}_se.report.tsv")
    params:
        prefix = opj(config["centrifuge_dir"], "{base}".format(base=config["centrifuge_base"])),
        tmp_out = opj(config["scratch_path"],"{sample}_se.out"),
        tmp_report = opj(config["scratch_path"],"{sample}_se.report.tsv")
    threads: 8
    resources:
        runtime = lambda wildcards, attempt: attempt**2*60
    message: "Running centrifuge on {wildcards.sample}"
    shell:
        """
        mkdir -p {config[scratch_path]}
        centrifuge -k {config[centrifuge_max_assignments]} -U {input[0]} -x {params.prefix} -S {params.tmp_out} \
         --report-file {params.tmp_report} -p {threads}
        mv {params.tmp_out} {output[0]}
        mv {params.tmp_report} {output[1]}
        """

#######################
## Remove host reads ##
#######################

rule filter_out_host:
    input:
        opj(config["data_path"],"{sample}_se.fq"),
        opj(config["results_path"],"centrifuge","{sample}_se.out")
    output:
        temp(opj(config["results_path"],"centrifuge","{sample}_se.filtered.read.ids")),
        opj(config["results_path"],"centrifuge","{sample}_se.filtered.fq")
    params:
        host_taxid = config['host_taxid']
    threads: 8
    resources:
        runtime = lambda wildcards, attempt: attempt**2*60
    message: "Removing host reads on {wildcards.sample}"
    shell:
        """
        cut -f 1,2,3 {input[1]} | grep -v $'\t'{params.host_taxid}$ | cut -f 1 > {output[0]}
        seqtk subseq {input[0]} {output[0]} > {output[1]}
        """

#####################################
## Generate kreports/krona reports ##
#####################################

rule centrifuge_kreport:
    input:
        f = opj(config["results_path"],"centrifuge","{sample}_se.out"),
        db = expand(opj(config["centrifuge_dir"],"{base}.{i}.cf"), i=[1,2,3], base=config["centrifuge_base"])
    output:
        opj(config["results_path"],"centrifuge","{sample}_se.report")
    params:
        min_score = config["centrifuge_min_score"],
        prefix = opj(config["centrifuge_dir"], "{base}".format(base=config["centrifuge_base"])),
    shell:
        """
        centrifuge-kreport --min-score {params.min_score} -x {params.prefix} {input.f} > {output[0]}
        """

rule centrifuge2krona:
    input:
        opj(config["results_path"],"centrifuge","{sample}_se.report"),
        opj(config["taxdb"],"krona","taxonomy.tab")
    output:
        opj(config["results_path"],"centrifuge","{sample}_se.krona.html")
    params:
        tax = opj(config["taxdb"],"krona")
    shell:
        """
        ktImportTaxonomy -m 3 -t 5 -tax {params.tax} -o {output[0]} {input[0]},{wildcards.sample}
        """

rule all_centrifuge_to_krona:
    input:
        f = expand(opj(config["results_path"],"centrifuge", "{sample}_se.report"),sample=Samples.keys()),
        h = expand(opj(config["results_path"],"centrifuge", "{sample}_se.html"),sample=Samples.keys()),
        t = opj(config["taxdb"],"krona","taxonomy.tab")
    output:
        opj(config["report_path"],"centrifuge","centrifuge.krona.html")
    params:
        tax = opj(config["taxdb"],"krona")
    run:
        input_string = ""
        for f in input.f:
            sample_run = os.path.basename(f).replace("_se.report","")
            print(sample_run,f)
            input_string+=" {},{}".format(f,sample_run)
        shell("ktImportTaxonomy -t 5 -m 3 -tax {params.tax} -o {output[0]} {input_string}")


##################################################
## Filter out genome sequences using Centrifuge ##
##################################################

rule centrifuge_sqlite_taxdb:
    """Creates a sqlite database for ete3 in the centrifuge path"""
    output:
        opj(config["taxdb"],"taxonomy","taxdb.sqlite"),
        opj(config["taxdb"],"taxonomy","taxdb.sqlite.traverse.pkl")
    message: "Creating ete3 sqlite taxonomy database in {output[0]}"
    shadow: "minimal"
    run:
        from ete3 import NCBITaxa
        shell("touch {output[0]}")
        ncbi_taxa = NCBITaxa(output[0])

rule centrifuge_filter:
    """Filter genomes by centrifuge read counts or abundance"""
    input:
        opj(config["results_path"],"centrifuge","{sample}_se.report.tsv"),
        opj(config["taxdb"],"taxonomy","taxdb.sqlite"),
        opj(config["centrifuge_dir"],"seqid2taxid.map")
    output:
        opj(config["results_path"],"centrifuge","{sample}_se.filtered_genomes")
    params:
        min_read_count = int(config["centrifuge_min_read_count"]),
        min_abundance = float(config["centrifuge_min_abundance"]),
        script = "../../scripts/centrifuge_filter_genomes.py",
        host_taxid = str(config["host_taxid"])
    shell:
        """
        python {params.script} -i {input[0]} -d {input[1]} -M {input[2]} -r {params.min_read_count} \
                               -a {params.min_abundance} -t {params.host_taxid} -o {output[0]}
        """

rule get_filtered_genome_seqs:
    """Extracts nucleotide fasta files for the filtered genomes"""
    input:
        genome_files = expand(opj(config["results_path"],"centrifuge","{sample}_se.filtered_genomes"), sample=Samples.keys()),
        fna = opj(config["centrifuge_dir"],"input-sequences.fna.gz")
    output:
        fna = opj(config["results_path"],"centrifuge","filtered","genomes.fna")
    params:
        out_dir = opj(config["results_path"],"centrifuge","filtered"),
        seqids = temp(opj(config["results_path"],"centrifuge","filtered","seqids"))
    run:
        shell("mkdir -p {params.out_dir}")
        df = pd.DataFrame()
        for f in input.genome_files:
            _df = pd.read_csv(f, sep="\t")
            df = pd.concat([df,_df], sort=True)
            # Make unique by seqid
            df = df.groupby("seq").first().reset_index()
            # Write seqids to file
            with open(params.seqids, 'w') as fhout:
                for seqid in df.seq:
                    fhout.write("{}\n".format(seqid))

        # Extract sequences
        shell("seqtk subseq {input.fna} {params.seqids} > {output.fna}")
        #df.to_csv(output.tab, sep="\t", index=False, header=True)
        #shell("rm {params.seqids}")